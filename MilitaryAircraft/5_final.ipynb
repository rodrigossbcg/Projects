{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-image: url('images/chain.jpg'); background-size: cover; border-radius: 20px; width: 100%;\">\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <center><h1 style=\"font-size: 50px; color: white; text-shadow: 0 0 5px black, 0 0 5px black;\"><b>5. Final Workflow</b></h1></center>\n",
    "    <center><h1 style=\"font-size: 30px; color: white;  text-shadow: 0 0 5px black, 0 0 5px black;\">Computer Vision</h1></center>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <br>\n",
    "    <div style=\"color: white; margin-left:  5%; font-size: 20px;\">\n",
    "        <p>Realizado por: </p>\n",
    "        <ul>\n",
    "            <li>Beatriz Santos, nº 108593</li>\n",
    "            <li>João Ferreira, nº 88639</li>\n",
    "            <li>Rodrigo Sarroeira, nº 92761</li>\n",
    "        </ul>\n",
    "    </div>        \n",
    "    <br>\n",
    "    <br>\n",
    "    <br><br></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_FILE = \"MobileNet/frozen_inference_graph.pb\"\n",
    "CONFIG_FILE = \"MobileNet/ssd_mobilenet_v2_coco_2018_03_29.pbtxt.txt\"\n",
    "CLASS_FILE = \"MobileNet/object_detection_classes_coco.txt\"\n",
    "VIDEO_FILE = \"videos/v1.mp4\"\n",
    "CONFIDENCE_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(CLASS_FILE, 'r') as f:\n",
    "    class_names = f.read().split('\\n')\n",
    "\n",
    "COLORS = np.random.uniform(0, 255, size=(len(class_names), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plane detector\n",
    "SSDmodel = cv2.dnn.readNet(model=MODEL_FILE,\n",
    "                           config=CONFIG_FILE,\n",
    "                           framework=\"TensorFlow\")\n",
    "\n",
    "# Plane classifier\n",
    "mobile_net = tf.keras.models.load_model(\"ClassNets\\MobileNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "videoStream = cv2.VideoCapture(VIDEO_FILE)\n",
    "width = int(videoStream.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(videoStream.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "out = cv2.VideoWriter('videos/output1.mp4', fourcc, 20.0, (width, height))\n",
    "classes = os.listdir(\"images/crop_new\")\n",
    "\n",
    "while videoStream.isOpened():\n",
    "    ret, frame = videoStream.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    img_height, img_width, channels = frame.shape\n",
    "    blob = cv2.dnn.blobFromImage(image=frame, size=(300, 300), swapRB=True)\n",
    "    SSDmodel.setInput(blob)\n",
    "    output = SSDmodel.forward()\n",
    "\n",
    "    for detection in output[0, 0, :, :]:\n",
    "        if detection[2] > CONFIDENCE_THRESHOLD:\n",
    "            class_id = detection[1]\n",
    "            class_name = class_names[int(class_id) - 1]\n",
    "            color = COLORS[int(class_id)]\n",
    "\n",
    "            bbox_x = int(detection[3] * img_width)\n",
    "            bbox_y = int(detection[4] * img_height)\n",
    "            bbox_width = int(detection[5] * img_width)\n",
    "            bbox_height = int(detection[6] * img_height)\n",
    "\n",
    "            plane = frame[bbox_y:bbox_y+bbox_height, bbox_x:bbox_x+bbox_width]\n",
    "            data = np.empty((1, 224, 224, 3))\n",
    "            data[0] = cv2.resize(plane, (224, 224), interpolation=cv2.INTER_AREA)\n",
    "            prediction = np.argmax(mobile_net.predict_on_batch(data))\n",
    "            cv2.rectangle(frame, (bbox_x, bbox_y), (bbox_width, bbox_height), color, thickness=2)\n",
    "            cv2.putText(frame, classes[prediction], (bbox_x, bbox_y - 5), cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
    "            out.write(frame)\n",
    "\n",
    "out.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
